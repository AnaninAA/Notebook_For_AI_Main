{"metadata":{"orig_nbformat":4,"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Зависимости\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.compose import ColumnTransformer\n\nfrom sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n\nfrom sklearn.metrics import mean_squared_error, f1_score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Генерируем уникальный seed\nmy_code = \"Kirsanov\"\nseed_limit = 2 ** 32\nmy_seed = int.from_bytes(my_code.encode(), \"little\") % seed_limit","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Читаем данные из файла\nexample_data = pd.read_csv(\"datasets/Fish.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"example_data.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Определим размер валидационной и тестовой выборок\nval_test_size = round(0.2*len(example_data))\nprint(val_test_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создадим обучающую, валидационную и тестовую выборки\nrandom_state = my_seed\ntrain_val, test = train_test_split(example_data, test_size=val_test_size, random_state=random_state)\ntrain, val = train_test_split(train_val, test_size=val_test_size, random_state=random_state)\nprint(len(train), len(val), len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Значения в числовых столбцах преобразуем к отрезку [0,1].\n# Для настройки скалировщика используем только обучающую выборку.\nnum_columns = ['Weight', 'Length1', 'Length2', 'Length3', 'Height', 'Width']\n\nct = ColumnTransformer(transformers=[('numerical', MinMaxScaler(), num_columns)], remainder='passthrough')\nct.fit(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Преобразуем значения, тип данных приводим к DataFrame\nsc_train = pd.DataFrame(ct.transform(train))\nsc_test = pd.DataFrame(ct.transform(test))\nsc_val = pd.DataFrame(ct.transform(val))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Устанавливаем названия столбцов\ncolumn_names = num_columns + ['Species']\nsc_train.columns = column_names\nsc_test.columns = column_names\nsc_val.columns = column_names","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sc_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Задание №1 - анализ деревьев принятия решений в задаче регрессии\n# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n# criterion : {“mse”, “friedman_mse”, “mae”, “poisson”}, default=”mse”\n# splitter : {“best”, “random”}, default=”best”\n# max_depth : int, default=None\n# min_samples_split : int or float, default=2\n# min_samples_leaf : int or float, default=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выбираем 4 числовых переменных, три их них будут предикторами, одна - зависимой переменной\nn = 4\nlabels = random.sample(num_columns, n)\n\ny_label = labels[0]\nx_labels = labels[1:]\n\nprint(x_labels)\nprint(y_label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Отберем необходимые параметры\nx_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = sc_train[y_label]\ny_test = sc_test[y_label]\ny_val = sc_val[y_label]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создайте 4 модели с различными критериями ветвления criterion: 'mse', 'friedman_mse', 'mae', 'poisson'.\n# Решите получившуюся задачу регрессии с помощью созданных моделей и сравните их эффективность.\n# При необходимости применяйте параметры splitter, max_depth, min_samples_split, min_samples_leaf\n# Укажите, какая модель решает задачу лучше других.","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_model1 = DecisionTreeRegressor(criterion='squared_error')\nr_model2 = DecisionTreeRegressor(criterion='friedman_mse', splitter='best', max_depth=3, min_samples_split=4, min_samples_leaf=0.5)\nr_model3 = DecisionTreeRegressor(criterion='absolute_error', splitter='random', max_depth=3, min_samples_split=4, min_samples_leaf=0.5)\nr_model4 = DecisionTreeRegressor(criterion='poisson', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r_models = []\nr_models.append(r_model1)\nr_models.append(r_model2)\nr_models.append(r_model3)\nr_models.append(r_model4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in r_models:\n    model.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mse_list = []\nfor model in r_models:\n    val_pred = model.predict(x_val)\n    mse = mean_squared_error(y_val, val_pred)\n    mse_list.append(mse)\n    print(mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Модель с минимальной MSE - \", mse_list.index(min(mse_list))+1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i_min = mse_list.index(min(mse_list))\nr_model = r_models[i_min]\nr_model.get_params()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = r_model.predict(x_test)\nmse = mean_squared_error(y_test, test_pred)\nprint(mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вывод на экран дерева tree.\n# max_depth - максимальная губина отображения, по умолчанию выводится дерево целиком.\nplot_tree(r_model, max_depth=1)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_tree(r_model)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Задание №2 - анализ деревьев принятия решений в задаче классификации\n# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n# criterion : {“gini”, “entropy”}, default=”gini”\n# splitter : {“best”, “random”}, default=”best”\n# max_depth : int, default=None\n# min_samples_split : int or float, default=2\n# min_samples_leaf : int or float, default=1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Выбираем 2 числовых переменных, которые будут параметрами элементов набора данных\n# Метка класса всегда 'Species'\nn = 2\nx_labels = random.sample(num_columns, n)\ny_label = 'Species'\n\nprint(x_labels)\nprint(y_label)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Отберем необходимые параметры\nx_train = sc_train[x_labels]\nx_test = sc_test[x_labels]\nx_val = sc_val[x_labels]\n\ny_train = sc_train[y_label]\ny_test = sc_test[y_label]\ny_val = sc_val[y_label]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Создайте 4 модели с различными критериями ветвления criterion : 'gini', 'entropy' и splitter : 'best', 'random'.\n# Решите получившуюся задачу классификации с помощью созданных моделей и сравните их эффективность.\n# При необходимости применяйте параметры max_depth, min_samples_split, min_samples_leaf\n# Укажите, какая модель решает задачу лучше других.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_model1 = DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1)\nd_model2 = DecisionTreeClassifier(criterion='gini', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1)\nd_model3 = DecisionTreeClassifier(criterion='entropy', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1)\nd_model4 = DecisionTreeClassifier(criterion='entropy', splitter='random', max_depth=None, min_samples_split=2, min_samples_leaf=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d_models = []\nd_models.append(d_model1)\nd_models.append(d_model2)\nd_models.append(d_model3)\nd_models.append(d_model4)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for model in d_models:\n    model.fit(x_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_list = []\nfor model in d_models:\n    val_pred = model.predict(x_val)\n    f1 = f1_score(y_val, val_pred, average='weighted')\n    f1_list.append(f1)\n    print(f1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Модель с минимальной F1 - \", f1_list.index(min(f1_list))+1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"i_min = f1_list.index(min(f1_list))\nd_model = d_models[i_min]\nd_model.get_params()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = d_model.predict(x_test)\nf1 = f1_score(y_test, test_pred, average='weighted')\nprint(f1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Вывод на экран дерева tree.\n# max_depth - максимальная губина отображения, по умолчанию выводится дерево целиком.\nplot_tree(d_model, max_depth=1)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_tree(d_model)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}