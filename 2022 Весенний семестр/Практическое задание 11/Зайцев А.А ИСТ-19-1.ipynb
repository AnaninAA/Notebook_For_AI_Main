{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание на повторение материала предыдущего семестра"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зависимости\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, f1_score, silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем уникальный seed\n",
    "my_code = \"Зайцев\"\n",
    "seed_limit = 2 ** 32\n",
    "my_seed = int.from_bytes(my_code.encode(), \"little\") % seed_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Данные загружены отсюда: https://www.kaggle.com/dwdkills/russian-demography\n",
    "# Читаем данные из файла\n",
    "example_data = pd.read_csv(\"datasets/russian_demography.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"year\" - год (1990-2017)\n",
    "# \"region\" - название региона\n",
    "# \"npg\" - естественный прирост населения на 1000 человек\n",
    "# \"birth_rate\" - количество рождений на 1000 человек\n",
    "# \"death_rate\" - количество смертей на 1000 человек\n",
    "# \"gdw\" - коэффициент демографической нагрузки на 100 человек (Отношение числа нетрудоспособных к числу трудоспособных).\n",
    "# \"urbanization\" - процент городского населения\n",
    "\n",
    "example_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Так как список регионов меняется от года к году, в данных есть строки без значений. Удалим их\n",
    "example_data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим размер валидационной и тестовой выборок\n",
    "val_test_size = round(0.2*len(example_data))\n",
    "print(val_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим обучающую, валидационную и тестовую выборки\n",
    "random_state = my_seed\n",
    "train_val, test = train_test_split(example_data, test_size=val_test_size, random_state=random_state)\n",
    "train, val = train_test_split(train_val, test_size=val_test_size, random_state=random_state)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Значения в числовых столбцах преобразуем к отрезку [0,1].\n",
    "# Для настройки скалировщика используем только обучающую выборку.\n",
    "columns_to_scale = ['year', 'npg', 'birth_rate', 'death_rate', 'gdw', 'urbanization']\n",
    "\n",
    "ct = ColumnTransformer(transformers=[('numerical', MinMaxScaler(), columns_to_scale)], remainder='passthrough')\n",
    "ct.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем значения, тип данных приводим к DataFrame\n",
    "sc_train = pd.DataFrame(ct.transform(train))\n",
    "sc_test = pd.DataFrame(ct.transform(test))\n",
    "sc_val = pd.DataFrame(ct.transform(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Устанавливаем названия столбцов\n",
    "column_names = columns_to_scale + ['region']\n",
    "sc_train.columns = column_names\n",
    "sc_test.columns = column_names\n",
    "sc_val.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспоминаем алгоритмы решения задачи регрессии\n",
    "r_models = []\n",
    "\n",
    "# Линейная регрессия\n",
    "# Для использования регуляризации, вместо LinearRegression используем Lasso, Ridge или ElasticNet\n",
    "# Параметр alpha - коэффициент регуляризации для Lasso и Ridge, по умолчанию равен 1\n",
    "# Для ElasticNet, если регуляризация иммет вид a*L1+b*L2, то\n",
    "# параметр alpha = a + b, по умолчанию равен 1\n",
    "# параметр l1_ratio = a / (a + b), по умолчанию равен 0.5\n",
    "r_models.append(LinearRegression())\n",
    "r_models.append(Lasso(alpha=1.0))\n",
    "r_models.append(Ridge(alpha=1.0))\n",
    "r_models.append(ElasticNet(alpha=1.0, l1_ratio=0.5))\n",
    "\n",
    "# K ближайших соседей\n",
    "# Параметр n_neighbors - количество соседей, по умолчания равен 5\n",
    "r_models.append(KNeighborsRegressor(n_neighbors=5))\n",
    "r_models.append(KNeighborsRegressor(n_neighbors=10))\n",
    "r_models.append(KNeighborsRegressor(n_neighbors=15))\n",
    "\n",
    "# Метод опорных векторов\n",
    "# Параметр kernel опредеяет вид ядра преобразования\n",
    "r_models.append(SVR(kernel='linear'))\n",
    "r_models.append(SVR(kernel='poly'))\n",
    "r_models.append(SVR(kernel='rbf'))\n",
    "r_models.append(SVR(kernel='sigmoid'))\n",
    "\n",
    "# Деревья решений\n",
    "# Параметр criterion - критерий качества ветвления: 'mse', 'friedman_mse', 'mae', 'poisson'\n",
    "r_models.append(DecisionTreeRegressor(criterion='squared_error'))\n",
    "r_models.append(DecisionTreeRegressor(criterion='friedman_mse'))\n",
    "r_models.append(DecisionTreeRegressor(criterion='absolute_error'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим предикторы и зависимую переменную\n",
    "x_labels = column_names[0:-2]\n",
    "y_labels = ['urbanization']\n",
    "\n",
    "x_train = sc_train[x_labels]\n",
    "x_test = sc_test[x_labels]\n",
    "x_val = sc_val[x_labels]\n",
    "\n",
    "y_train = np.ravel(sc_train[y_labels])\n",
    "y_test = np.ravel(sc_test[y_labels])\n",
    "y_val = np.ravel(sc_val[y_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модели\n",
    "for model in r_models:\n",
    "    print(model)\n",
    "    model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Оценииваем качество работы моделей на валидационной выборке.\n",
    "mses = []\n",
    "for model in r_models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    mse = mean_squared_error(y_val, val_pred)\n",
    "    mses.append(mse)\n",
    "    print(model, '\\t', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель\n",
    "i_min = mses.index(min(mses))\n",
    "best_r_model = r_models[i_min]\n",
    "best_r_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислим ошибку лучшей модели на тестовой выборке.\n",
    "test_pred = best_r_model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, test_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспоминаем алгоритмы решения задачи классификации\n",
    "c_models = []\n",
    "\n",
    "# Логистическая регрессия\n",
    "# Параметр penalty - тип регуляризации: 'l1', 'l2', 'elasticnet', 'none'}, по умолчанию 'l2'\n",
    "# Для некоторых типов регуляризации доступны не все алгоритмы (параметр solver)\n",
    "# Для elasticnet регуляризации необходимо уазывать параметр l1_ratio (0 - l2, 1 - l1)\n",
    "c_models.append(LogisticRegression(penalty='none', solver='saga', max_iter=500))\n",
    "c_models.append(LogisticRegression(penalty='l1', solver='saga', max_iter=500))\n",
    "c_models.append(LogisticRegression(penalty='l2', solver='saga'))\n",
    "c_models.append(LogisticRegression(penalty='elasticnet', l1_ratio=0.5, solver='saga'))\n",
    "c_models.append(LogisticRegression())\n",
    "\n",
    "# Наивный байесовский классификатор\n",
    "# Параметр alpha - параметр сглаживания, по умолчанию равен 1 (сглаживание Лапласа)\n",
    "c_models.append(MultinomialNB(alpha=0.0))\n",
    "c_models.append(MultinomialNB(alpha=0.5))\n",
    "c_models.append(MultinomialNB(alpha=1.0))\n",
    "\n",
    "# K ближайших соседей\n",
    "# Параметр n_neighbors - количество соседей, по умолчания равен 5\n",
    "c_models.append(KNeighborsClassifier(n_neighbors=5))\n",
    "c_models.append(KNeighborsClassifier(n_neighbors=10))\n",
    "c_models.append(KNeighborsClassifier(n_neighbors=15))\n",
    "\n",
    "# Метод опорных векторов\n",
    "# Параметр kernel опредеяет вид ядра преобразования\n",
    "c_models.append(SVC(kernel='linear'))\n",
    "c_models.append(SVC(kernel='poly'))\n",
    "c_models.append(SVC(kernel='rbf'))\n",
    "c_models.append(SVC(kernel='sigmoid'))\n",
    "\n",
    "# Деревья решений\n",
    "# Параметр criterion - критерий качества ветвления: 'gini', 'entropy'\n",
    "# Параметр splitter - стартегия ветвления: 'best', 'random'\n",
    "c_models.append(DecisionTreeClassifier(criterion='gini', splitter='best'))\n",
    "c_models.append(DecisionTreeClassifier(criterion='gini', splitter='random'))\n",
    "c_models.append(DecisionTreeClassifier(criterion='entropy', splitter='best'))\n",
    "c_models.append(DecisionTreeClassifier(criterion='entropy', splitter='random'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим предикторы и метки классов\n",
    "x_labels = column_names[0:-1]\n",
    "y_labels = ['region']\n",
    "\n",
    "x_train = sc_train[x_labels]\n",
    "x_test = sc_test[x_labels]\n",
    "x_val = sc_val[x_labels]\n",
    "\n",
    "y_train = np.ravel(sc_train[y_labels])\n",
    "y_test = np.ravel(sc_test[y_labels])\n",
    "y_val = np.ravel(sc_val[y_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модели\n",
    "for model in c_models:\n",
    "    print(model)\n",
    "    model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценииваем качество работы моделей на валидационной выборке.\n",
    "f1s = []\n",
    "for model in c_models:\n",
    "    val_pred = model.predict(x_val)\n",
    "    f1 = f1_score(y_val, val_pred, average='weighted')\n",
    "    f1s.append(f1)\n",
    "    print(model, '\\t', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель\n",
    "i_max = f1s.index(max(f1s))\n",
    "best_c_model = c_models[i_max]\n",
    "best_c_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислим ошибку лучшей модели на тестовой выборке.\n",
    "test_pred = best_c_model.predict(x_test)\n",
    "f1 = f1_score(y_test, test_pred, average='weighted')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспоминаем алгоритм решения задачи кластеризации - метод k-средних\n",
    "# Параметр n_clusters - количество кластеров, по умолчанию равен 8\n",
    "k_models = []\n",
    "k_models.append(KMeans(n_clusters=5))\n",
    "k_models.append(KMeans(n_clusters=8))\n",
    "k_models.append(KMeans(n_clusters=20))\n",
    "k_models.append(KMeans(n_clusters=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим используемые параметры\n",
    "x_labels = column_names[0:-1]\n",
    "x = pd.concat([sc_train[x_labels], sc_val[x_labels], sc_test[x_labels]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем кластеризацию\n",
    "for model in k_models:\n",
    "    model.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим качество результата\n",
    "sils = []\n",
    "for model in k_models:\n",
    "    cluster_labels = model.predict(x)\n",
    "    s = silhouette_score(x, cluster_labels)\n",
    "    sils.append(s)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель\n",
    "i_max = sils.index(max(sils))\n",
    "best_k_model = k_models[i_max]\n",
    "print(best_k_model)\n",
    "print(sils[i_max])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание №1 - анализ моделей для задачи регрессии\n",
    "# Общий список моделей\n",
    "r_models = [\n",
    "    LinearRegression(),\n",
    "    Lasso(alpha=1.0),\n",
    "    Lasso(alpha=0.5),\n",
    "    Ridge(alpha=1.0),\n",
    "    Ridge(alpha=0.5),\n",
    "    ElasticNet(alpha=1.0, l1_ratio=0.5),\n",
    "    ElasticNet(alpha=1.0, l1_ratio=0.25),\n",
    "    ElasticNet(alpha=1.0, l1_ratio=0.75),\n",
    "    ElasticNet(alpha=0.5, l1_ratio=0.5),\n",
    "    ElasticNet(alpha=0.5, l1_ratio=0.25),\n",
    "    ElasticNet(alpha=0.5, l1_ratio=0.75),\n",
    "    KNeighborsRegressor(n_neighbors=5),\n",
    "    KNeighborsRegressor(n_neighbors=10),\n",
    "    KNeighborsRegressor(n_neighbors=15),\n",
    "    KNeighborsRegressor(n_neighbors=20),\n",
    "    KNeighborsRegressor(n_neighbors=25),\n",
    "    SVR(kernel='linear'),\n",
    "    SVR(kernel='poly'),\n",
    "    SVR(kernel='rbf'),\n",
    "    SVR(kernel='sigmoid'),\n",
    "    DecisionTreeRegressor(criterion='squared_error'),\n",
    "    DecisionTreeRegressor(criterion='friedman_mse'),\n",
    "    DecisionTreeRegressor(criterion='absolute_error')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор моделей для задания\n",
    "n = 4\n",
    "random.seed(my_seed)\n",
    "my_models1 = random.sample(r_models, n)\n",
    "print(my_models1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Загрузим данные для задачи регрессии\n",
    "data = pd.read_csv(\"datasets/weather.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зависимая переменная для всех одна и та же. Предикторы выбираем случайнм образом.\n",
    "columns = list(data.columns)\n",
    "n_x = 5\n",
    "\n",
    "y_label = 'water_level'\n",
    "x_labels = random.sample(columns[1:], n_x)\n",
    "\n",
    "print(x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуйте значения всех необходимых параметров к отрезку [0,1].\n",
    "# Решите получившуюся задачу регрессии с помощью выбранных моделей и сравните их эффективность.\n",
    "# Укажите, какая модель решает задачу лучше других."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Задание №2 - анализ моделей для задачи классификации\n",
    "# Общий список моделей\n",
    "c_models = [\n",
    "    LogisticRegression(penalty='none', solver='saga'),\n",
    "    LogisticRegression(penalty='l1', solver='saga'),\n",
    "    LogisticRegression(penalty='l2', solver='saga'),\n",
    "    LogisticRegression(penalty='elasticnet', l1_ratio=0.25, solver='saga'),\n",
    "    LogisticRegression(penalty='elasticnet', l1_ratio=0.5, solver='saga'),\n",
    "    LogisticRegression(penalty='elasticnet', l1_ratio=0.75, solver='saga'),\n",
    "    LogisticRegression(),\n",
    "    MultinomialNB(alpha=0.0),\n",
    "    MultinomialNB(alpha=0.25),\n",
    "    MultinomialNB(alpha=0.5),\n",
    "    MultinomialNB(alpha=0.75),\n",
    "    MultinomialNB(alpha=1.0),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    KNeighborsClassifier(n_neighbors=10),\n",
    "    KNeighborsClassifier(n_neighbors=15),\n",
    "    KNeighborsClassifier(n_neighbors=20),\n",
    "    KNeighborsClassifier(n_neighbors=25),\n",
    "    SVC(kernel='linear'),\n",
    "    SVC(kernel='poly'),\n",
    "    SVC(kernel='rbf'),\n",
    "    SVC(kernel='sigmoid'),\n",
    "    DecisionTreeClassifier(criterion='gini', splitter='best'),\n",
    "    DecisionTreeClassifier(criterion='gini', splitter='random'),\n",
    "    DecisionTreeClassifier(criterion='entropy', splitter='best'),\n",
    "    DecisionTreeClassifier(criterion='entropy', splitter='random')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбор моделей для задания\n",
    "n = 5\n",
    "my_models2 = random.sample(c_models, n)\n",
    "print(my_models2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Загрузим данные для задачи классификации\n",
    "data = pd.read_csv(\"datasets/zoo2.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Метка класса для всех одна и та же. Параметры выбираем случайнм образом.\n",
    "columns = list(data.columns)\n",
    "n_x = 8\n",
    "\n",
    "y_label = 'class_type'\n",
    "x_labels = random.sample(columns[1:-1], n_x)\n",
    "\n",
    "print(x_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = x_labels.copy()\n",
    "labels.append(y_label)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуйте значения всех необходимых параметров к отрезку [0,1].\n",
    "# Решите получившуюся задачу классификации с помощью выбранных моделей и сравните их эффективность.\n",
    "# Укажите, какая модель решает задачу лучше других.\n",
    "\n",
    "sec_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_test_size2 = round(0.2*len(sec_data))\n",
    "print(val_test_size2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = my_seed\n",
    "train_val2, test2 = train_test_split(sec_data, test_size=val_test_size2, random_state=random_state)\n",
    "sec_train, val2 = train_test_split(train_val2, test_size=val_test_size2, random_state=random_state)\n",
    "print(len(sec_train), len(val2), len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_scale2 = x_newlabels\n",
    "\n",
    "ct2 = ColumnTransformer(transformers=[('numerical', MinMaxScaler(), columns_to_scale2)], remainder='passthrough')\n",
    "ct2.fit(sec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_train2 = pd.DataFrame(ct2.transform(sec_train))\n",
    "sc_test2 = pd.DataFrame(ct2.transform(test2))\n",
    "sc_val2 = pd.DataFrame(ct2.transform(val2))\n",
    "column_names2 = columns_to_scale2 + ['class_type']\n",
    "sc_train2.columns = column_names2\n",
    "sc_test2.columns = column_names2\n",
    "sc_val2.columns = column_names2\n",
    "sc_val2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспоминаем алгоритмы решения задачи классификации\n",
    "c_models = []\n",
    "\n",
    "# Логистическая регрессия\n",
    "# Параметр penalty - тип регуляризации: 'l1', 'l2', 'elasticnet', 'none'}, по умолчанию 'l2'\n",
    "# Для некоторых типов регуляризации доступны не все алгоритмы (параметр solver)\n",
    "# Для elasticnet регуляризации необходимо уазывать параметр l1_ratio (0 - l2, 1 - l1)\n",
    "c_models.append(LogisticRegression(penalty='l1', solver='saga'))\n",
    "\n",
    "\n",
    "# K ближайших соседей\n",
    "# Параметр n_neighbors - количество соседей, по умолчания равен 5\n",
    "c_models.append(KNeighborsClassifier(n_neighbors=5))\n",
    "\n",
    "# Метод опорных векторов\n",
    "# Параметр kernel опредеяет вид ядра преобразования\n",
    "c_models.append(SVC(kernel='sigmoid'))\n",
    "\n",
    "# Деревья решений\n",
    "# Параметр criterion - критерий качества ветвления: 'gini', 'entropy'\n",
    "# Параметр splitter - стартегия ветвления: 'best', 'random'\n",
    "c_models.append(DecisionTreeClassifier())\n",
    "c_models.append(DecisionTreeClassifier(splitter='random'))\n",
    "c_models\n",
    "[LogisticRegression(penalty='l1', solver='saga'),\n",
    " KNeighborsClassifier(),\n",
    " SVC(kernel='sigmoid'),\n",
    " DecisionTreeClassifier(),\n",
    " DecisionTreeClassifier(splitter='random')]\n",
    "x_labels2 = column_names2[0:-1]\n",
    "y_labels2 = ['class_type']\n",
    "\n",
    "x_train2 = sc_train2[x_labels2]\n",
    "x_test2 = sc_test2[x_labels2]\n",
    "x_val2 = sc_val2[x_labels2]\n",
    "\n",
    "y_train2 = np.ravel(sc_train2[y_labels2])\n",
    "y_test2 = np.ravel(sc_test2[y_labels2])\n",
    "y_val2 = np.ravel(sc_val2[y_labels2])\n",
    "x_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модели\n",
    "for model2 in c_models:\n",
    "    print(model2)\n",
    "    model2.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценииваем качество работы моделей на валидационной выборке.\n",
    "f1s = []\n",
    "for model2 in c_models:\n",
    "    val_pred2 = model2.predict(x_val2)\n",
    "    f1 = f1_score(y_val2, val_pred2, average='weighted')\n",
    "    f1s.append(f1)\n",
    "    print(model2, '\\t', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель\n",
    "i_max = f1s.index(max(f1s))\n",
    "best_c_model = c_models[i_max]\n",
    "best_c_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычислим ошибку лучшей модели на тестовой выборке.\n",
    "test_pred2 = best_c_model.predict(x_test2)\n",
    "f1 = f1_score(y_test2, test_pred2, average='weighted')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вспоминаем алгоритм решения задачи кластеризации - метод k-средних\n",
    "# Параметр n_clusters - количество кластеров, по умолчанию равен 8\n",
    "k_models = []\n",
    "k_models.append(KMeans(n_clusters=5))\n",
    "k_models.append(KMeans(n_clusters=8))\n",
    "k_models.append(KMeans(n_clusters=20))\n",
    "k_models.append(KMeans(n_clusters=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выделим используемые параметры\n",
    "x_labels2 = column_names2[0:-1]\n",
    "x = pd.concat([sc_train2[x_labels2], sc_val2[x_labels2], sc_test2[x_labels2]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Произведем кластеризацию\n",
    "for model in k_models:\n",
    "    model.fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оценим качество результата\n",
    "sils = []\n",
    "for model2 in k_models:\n",
    "    cluster_labels = model2.predict(x)\n",
    "    s = silhouette_score(x, cluster_labels)\n",
    "    sils.append(s)\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем лучшую модель\n",
    "i_max = sils.index(max(sils))\n",
    "best_k_model = k_models[i_max]\n",
    "print(best_k_model)\n",
    "print(sils[i_max])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
