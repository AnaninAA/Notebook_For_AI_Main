{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Species  Weight  Length1  Length2  Length3   Height   Width\n",
      "0     Bream   242.0     23.2     25.4     30.0  11.5200  4.0200\n",
      "1     Bream   290.0     24.0     26.3     31.2  12.4800  4.3056\n",
      "2     Bream   340.0     23.9     26.5     31.1  12.3778  4.6961\n",
      "3     Bream   363.0     26.3     29.0     33.5  12.7300  4.4555\n",
      "4     Bream   430.0     26.5     29.0     34.0  12.4440  5.1340\n",
      "..      ...     ...      ...      ...      ...      ...     ...\n",
      "154   Smelt    12.2     11.5     12.2     13.4   2.0904  1.3936\n",
      "155   Smelt    13.4     11.7     12.4     13.5   2.4300  1.2690\n",
      "156   Smelt    12.2     12.1     13.0     13.8   2.2770  1.2558\n",
      "157   Smelt    19.7     13.2     14.3     15.2   2.8728  2.0672\n",
      "158   Smelt    19.9     13.8     15.0     16.2   2.9322  1.8792\n",
      "\n",
      "[159 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# Набор данных взят с https://www.kaggle.com/aungpyaeap/fish-market\n",
    "# Параметры нескольких популярных промысловых рыб\n",
    "# length 1 = Body height\n",
    "# length 2 = Total Length\n",
    "# length 3 = Diagonal Length\n",
    "fish_data = pd.read_csv(\"datasets/Fish.csv\", delimiter=',')\n",
    "print(fish_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Length1  Length2  Length3   Height   Width  Weight\n",
      "0       23.2     25.4     30.0  11.5200  4.0200   242.0\n",
      "1       24.0     26.3     31.2  12.4800  4.3056   290.0\n",
      "2       23.9     26.5     31.1  12.3778  4.6961   340.0\n",
      "3       26.3     29.0     33.5  12.7300  4.4555   363.0\n",
      "4       26.5     29.0     34.0  12.4440  5.1340   430.0\n",
      "..       ...      ...      ...      ...     ...     ...\n",
      "154     11.5     12.2     13.4   2.0904  1.3936    12.2\n",
      "155     11.7     12.4     13.5   2.4300  1.2690    13.4\n",
      "156     12.1     13.0     13.8   2.2770  1.2558    12.2\n",
      "157     13.2     14.3     15.2   2.8728  2.0672    19.7\n",
      "158     13.8     15.0     16.2   2.9322  1.8792    19.9\n",
      "\n",
      "[159 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Выделим две переменных\n",
    "x_label = ['Length1','Length2','Length3','Height','Width']\n",
    "y_label = 'Weight'\n",
    "data = fish_data[[*x_label, y_label]]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# Определим размер валидационной и тестовой выборок\n",
    "val_test_size = round(0.2*len(data))\n",
    "print(val_test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем уникальный seed\n",
    "my_code = \"Маргарян\"\n",
    "seed_limit = 2 ** 32\n",
    "my_seed = int.from_bytes(my_code.encode(), \"little\") % seed_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95 32 32\n"
     ]
    }
   ],
   "source": [
    "# Создадим обучающую, валидационную и тестовую выборки\n",
    "random_state = my_seed\n",
    "train_val, test = train_test_split(data, test_size=val_test_size, random_state=random_state)\n",
    "train, val = train_test_split(train_val, test_size=val_test_size, random_state=random_state)\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразуем данные к ожидаемому библиотекой skleran формату\n",
    "train_x = np.array(train[x_label])\n",
    "train_y = np.array(train[y_label]).reshape(-1,1)\n",
    "\n",
    "val_x = np.array(val[x_label])\n",
    "val_y = np.array(val[y_label]).reshape(-1,1)\n",
    "\n",
    "test_x = np.array(test[x_label])\n",
    "test_y = np.array(test[y_label]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Результат не очень хорош для интерпретации, попробуем сначала нормировать значения\n",
    "scaler_x = MinMaxScaler().fit(train_x)\n",
    "scaled_train_x = scaler_x.transform(train_x)\n",
    "\n",
    "scaler_y = MinMaxScaler().fit(train_y)\n",
    "scaled_train_y = scaler_y.transform(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Строим модель и выводим результаты для нормированных данных\n",
    "model1 = linear_model.LinearRegression()\n",
    "model1.fit(scaled_train_x, scaled_train_y)\n",
    "\n",
    "y = 0\n",
    "for i in range(len(x_label)):\n",
    "    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\n",
    "y += model1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006057597120728052\n"
     ]
    }
   ],
   "source": [
    "# Проверим результат на валидационной выборке\n",
    "scaled_val_x = scaler_x.transform(val_x)\n",
    "scaled_val_y = scaler_y.transform(val_y)\n",
    "\n",
    "val_predicted = model1.predict(scaled_val_x)\n",
    "\n",
    "mse1 = mean_squared_error(scaled_val_y, val_predicted)\n",
    "print(mse1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Построим модель линейной регресси с L1-регуляризацией и выведем результаты для нормированных данных.\n",
    "model2 = linear_model.Lasso(alpha=0.01)\n",
    "model2.fit(scaled_train_x, scaled_train_y)\n",
    "\n",
    "y = 0\n",
    "for i in range(len(x_label)):\n",
    "    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\n",
    "y += model2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010692497483362965\n"
     ]
    }
   ],
   "source": [
    "# Проверим результат на валидационной выборке\n",
    "scaled_val_x = scaler_x.transform(val_x)\n",
    "scaled_val_y = scaler_y.transform(val_y)\n",
    "\n",
    "val_predicted = model2.predict(scaled_val_x)\n",
    "\n",
    "mse2 = mean_squared_error(scaled_val_y, val_predicted)\n",
    "print(mse2)\n",
    "# Можете поэкспериментировать со значением параметра alpha, чтобы уменьшить ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Построим модель линейной регресси с L2-регуляризацией и выведем результаты для нормированных данных\n",
    "model3 = linear_model.Ridge(alpha=0.01)\n",
    "model3.fit(scaled_train_x, scaled_train_y)\n",
    "\n",
    "y = 0\n",
    "for i in range(len(x_label)):\n",
    "    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\n",
    "y += model3.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0059335895163704\n"
     ]
    }
   ],
   "source": [
    "# Проверим результат на валидационной выборке\n",
    "scaled_val_x = scaler_x.transform(val_x)\n",
    "scaled_val_y = scaler_y.transform(val_y)\n",
    "\n",
    "val_predicted = model3.predict(scaled_val_x)\n",
    "\n",
    "mse3 = mean_squared_error(scaled_val_y, val_predicted)\n",
    "print(mse3)\n",
    "# Можете поэкспериментировать со значением параметра alpha, чтобы уменьшить ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Построим модель линейной регресси с ElasticNet-регуляризацией и выведем результаты для нормированных данных\n",
    "model4 = linear_model.ElasticNet(alpha=0.01, l1_ratio = 0.01)\n",
    "model4.fit(scaled_train_x, scaled_train_y)\n",
    "\n",
    "y = 0\n",
    "for i in range(len(x_label)):\n",
    "    y += model1.coef_[0][i] * np.linspace(min(scaled_train_x[i]), max(scaled_train_x[i]), 100)\n",
    "y += model4.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0063758724971180345\n"
     ]
    }
   ],
   "source": [
    "# Проверим результат на валидационной выборке\n",
    "scaled_val_x = scaler_x.transform(val_x)\n",
    "scaled_val_y = scaler_y.transform(val_y)\n",
    "\n",
    "val_predicted = model4.predict(scaled_val_x)\n",
    "\n",
    "mse4 = mean_squared_error(scaled_val_y, val_predicted)\n",
    "print(mse4)\n",
    "# Можете поэкспериментировать со значениями параметров alpha и l1_ratio, чтобы уменьшить ошибку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.006057597120728052 0.010692497483362965 0.0059335895163704 0.0063758724971180345\n"
     ]
    }
   ],
   "source": [
    "# Выведем ошибки для моделей на нормированных данных\n",
    "print(mse1, mse2, mse3, mse4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01150786312229798\n"
     ]
    }
   ],
   "source": [
    "# Минимальное значение достигается для второй модели, получим итоговую величину ошибки на тестовой выборке\n",
    "scaled_test_x = scaler_x.transform(test_x)\n",
    "scaled_test_y = scaler_y.transform(test_y)\n",
    "\n",
    "test_predicted = model2.predict(scaled_test_x)\n",
    "\n",
    "mse_test = mean_squared_error(scaled_test_y, test_predicted)\n",
    "print(mse_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
